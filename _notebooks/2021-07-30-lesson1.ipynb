{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de3ae24",
   "metadata": {
    "id": "8a3622fa"
   },
   "source": [
    "# Lesson 1 Notes\n",
    "> notes for the fast.ai 2020 course\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [fastai course]\n",
    "- image: images/fastai.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93beea9d",
   "metadata": {},
   "source": [
    "## What you don't need, to deep learning\n",
    "Myth(don't need)| Truth\n",
    ":---------------|:------\n",
    "Lots of math    | Just high school math is sufficient\n",
    "Lots of data    | We've seen record-breaking results with <50 items of data\n",
    "Lots of expensive computers | You can get what you need for state of the art work for free\n",
    "\n",
    "A lot of world class research projects have come out of the fastai students based on a single GPU, using small data or without a traditional background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26129e32",
   "metadata": {},
   "source": [
    "## Where is deep learning the best known approach?\n",
    "![](../images/AI_the_best.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11b4cd",
   "metadata": {},
   "source": [
    "## History\n",
    "\n",
    "##### The Start\n",
    "In 1943, Warren McCulloch and Walter Pitts developed a mathematical model of an artificial neuron.\n",
    "\n",
    "In 1957, Frank Rosenblatt built the first device that actually used these principles, *the Mark I Perceptron* at Cornell. \n",
    ">We are now about to witness the birth of such a machine–-a machine capable of perceiving, recognizing and identifying its surroundings without any human training or control. \n",
    "> -- <cite>Frank Rosenblatt</cite>\n",
    "\n",
    "##### The First AI Winter\n",
    "1969, Marvin Minsky adn Seymour Papert wrote a book called *Perceptrons* and pointed out that *a single layer of a NN cannot learn some simple but critical functions (such as XOR) and using multiple layers of the devices would allow these limitations to be addressed*. Unfortunately, only the first of these insights was widely recognized.\n",
    "##### The Second Winter\n",
    "In theory, adding just one extra layer of neurons was enough to allow any mathematical function to be approximated with these neural networks, but in practice such networks were often too big and too slow to be useful. Although researchers showed 30 years ago that to get practical good performance you need to use even more layers of neurons, it is only in the last decade that this principle has been more widely appreciated and applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cc79c",
   "metadata": {
    "id": "33fde6f9"
   },
   "source": [
    "## The fast.ai Learning Philosophy\n",
    "![](../images/bat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628be1b8",
   "metadata": {},
   "source": [
    "## Projects and Mindset\n",
    "It helps to focus on your hobbies and passions–-setting yourself four or five little projects rather than striving to solve a big, grand problem tends to work better when you're getting started.\n",
    "\n",
    "## The Software: PyTorch, fastai, and Jupyter\n",
    "fastai is built top of PyTorch and these are written in Python and it's the language we will use during this  course. Many people think that fastai is just for beginners and teachers but it's actually using layered API which makes it infinite customizable and practical for every purpose.\n",
    "\n",
    "[Jupyter Notebook](https://jupyter.org/) is coding environment often used by DL people. It's easier to experiment things using Jupyter Notebooks than running Python code in terminal. Linux highly recommended.\n",
    "\n",
    "## Questionnaire\n",
    "After every section there are questionnaire which makes sure that you learned the most important things. It doesn't matter how many you get right but it just confirms that you haven't missed anything important. If you don't understand something after some time just continue and come back after a few chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dcb81",
   "metadata": {},
   "source": [
    "## What Is Machine Learning?\n",
    "*The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps.*\n",
    "\n",
    "In 1949, an IBM researcher named Arthur Samuel started working on machine learning. \n",
    "\n",
    "By 1961 his checkers-playing program beat the Connecticut state champion.\n",
    "\n",
    "In his classic 1962 essay \"Artificial Intelligence: A Frontier of Automation\", he wrote:\n",
    "> : Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.\n",
    "\n",
    "* the effectiveness → Loss \n",
    "* weight assignment → parameters of Neural Networks\n",
    "* performance → predictions\n",
    "* mechanism for altering the weight assignment → stochastic gradient descent (SGD)\n",
    "* maximize the performance → Minimize the Loss\n",
    "\n",
    "![](../images/ml.png)\n",
    "\n",
    "> Note: Neural networks and SGD are nearly entirely relying on addition and multiplication. Not complex math! And this learning approach only creates *predictions*.\n",
    "\n",
    "##### Limitations Inherent To Machine Learning\n",
    "* A model cannot be created without data.\n",
    "* A model can only learn to operate on the patterns seen in the input data used to train it.\n",
    "* This learning approach only creates predictions, not recommended actions.\n",
    "* It's not enough to just have examples of input data; we need labels for that data too"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2021-07-18-myth.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
